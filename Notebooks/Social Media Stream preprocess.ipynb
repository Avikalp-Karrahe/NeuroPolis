{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPIWqPY6sj878OBfxAwjHdW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"ww6IhiFuTuLE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1744585388150,"user_tz":420,"elapsed":474,"user":{"displayName":"Avikalp Karrahe","userId":"14204401851323774624"}},"outputId":"4256967f-1116-49a0-c49c-e13eb3c564dc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Initial dataframe shape: (50000, 5)\n","   user_id                 text            timestamp   latitude   longitude\n","0   148149     fire in downtown  2023-01-01 00:00:00  37.891326 -122.119823\n","1   133822     fire in downtown  2023-01-01 00:01:00  37.261545 -121.592279\n","2   117131  emergency in Zone A  2023-01-01 00:02:00  37.976165 -122.425660\n","3   197271     flood near river  2023-01-01 00:03:00  37.217171 -121.747097\n","4   105884      earthquake felt  2023-01-01 00:04:00  37.812096 -121.624895\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 50000 entries, 0 to 49999\n","Data columns (total 5 columns):\n"," #   Column     Non-Null Count  Dtype  \n","---  ------     --------------  -----  \n"," 0   user_id    50000 non-null  int64  \n"," 1   text       50000 non-null  object \n"," 2   timestamp  50000 non-null  object \n"," 3   latitude   50000 non-null  float64\n"," 4   longitude  50000 non-null  float64\n","dtypes: float64(2), int64(1), object(2)\n","memory usage: 1.9+ MB\n","None\n"]}],"source":["import pandas as pd\n","import re\n","\n","# Load the Social Media Stream CSV file\n","df = pd.read_csv('social_media_stream.csv')\n","\n","# Display basic information about the dataset\n","print(\"Initial dataframe shape:\", df.shape)\n","print(df.head())\n","print(df.info())\n"]},{"cell_type":"code","source":["\n","# Remove duplicate rows to ensure data uniqueness\n","df.drop_duplicates(inplace=True)\n","print(\"Shape after removing duplicates:\", df.shape)\n","\n","# Remove rows where the 'text' column (tweet content) is missing\n","if 'text' in df.columns:\n","    df = df[df['text'].notnull()]\n","    print(\"Shape after filtering out missing text entries:\", df.shape)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZV-atWgvY3md","executionInfo":{"status":"ok","timestamp":1744585391741,"user_tz":420,"elapsed":21,"user":{"displayName":"Avikalp Karrahe","userId":"14204401851323774624"}},"outputId":"c7bd7637-206a-4171-9688-ea043518183a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape after removing duplicates: (50000, 5)\n","Shape after filtering out missing text entries: (50000, 5)\n"]}]},{"cell_type":"code","source":["# Convert the 'timestamp' column to a datetime object if it exists, and remove invalid entries\n","if 'timestamp' in df.columns:\n","    df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n","    df = df[df['timestamp'].notnull()]\n","    print(\"Shape after cleaning timestamps:\", df.shape)\n","\n","# Define a helper function for text cleaning\n","def clean_text(text):\n","    # Remove URLs\n","    text = re.sub(r'http\\S+', '', text)\n","    # Remove non-alphanumeric characters (keep only letters, numbers, and spaces)\n","    text = re.sub(r'[^\\w\\s]', '', text)\n","    # Remove extra whitespace\n","    text = re.sub(r'\\s+', ' ', text)\n","    return text.strip().lower()\n","\n","# Clean the text and store it in a new column 'clean_text'\n","if 'text' in df.columns:\n","    df['clean_text'] = df['text'].apply(clean_text)\n","    print(\"Shape after cleaning text and filtering short entries:\", df.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sSb_p34VY57J","executionInfo":{"status":"ok","timestamp":1744585394115,"user_tz":420,"elapsed":120,"user":{"displayName":"Avikalp Karrahe","userId":"14204401851323774624"}},"outputId":"f426e9cc-e788-4280-aa4d-3af2dfbad36c"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape after cleaning timestamps: (50000, 5)\n","Shape after cleaning text and filtering short entries: (50000, 6)\n"]}]},{"cell_type":"code","source":["\n","# Save the cleaned DataFrame to a new CSV file\n","output_file = 'social_media_stream_cleaned.csv'\n","df.to_csv(output_file, index=False)\n","print(f\"Cleaned Social Media Stream data saved successfully at {output_file}.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rDdZfHrAZEea","executionInfo":{"status":"ok","timestamp":1744585415248,"user_tz":420,"elapsed":207,"user":{"displayName":"Avikalp Karrahe","userId":"14204401851323774624"}},"outputId":"6257e131-b48c-42b3-a185-424f6c1219ff"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Cleaned Social Media Stream data saved successfully at social_media_stream_cleaned.csv.\n"]}]}]}